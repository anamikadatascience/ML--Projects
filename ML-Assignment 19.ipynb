{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f091ca",
   "metadata": {},
   "source": [
    "1. A set of one-dimensional data points is given to you: 5, 10, 15, 20, 25, 30, 35. Assume that k = 2 and that the first set of random centroid is 15, 32, and that the second set is 12, 30.\n",
    "a) Using the k-means method, create two clusters for each set of centroid described above.\n",
    "b) For each set of centroid values, calculate the SSE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3bcbd",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "Using the k-means method with the first set of centroids (15, 32):\n",
    "\n",
    "Cluster 1: 5, 10, 15, 20\n",
    "Cluster 2: 25, 30, 35\n",
    "Using the k-means method with the second set of centroids (12, 30):\n",
    "\n",
    "Cluster 1: 5, 10, 15\n",
    "Cluster 2: 20, 25, 30, 35\n",
    "b)\n",
    "For the first set of centroids (15, 32):\n",
    "SSE = (0^2 + 2^2 + 0^2 + 2^2 + 2^2 + 2^2 + 3^2) = 23\n",
    "\n",
    "For the second set of centroids (12, 30):\n",
    "SSE = (9^2 + 20^2 + 15^2 + 10^2) = 966"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16058a",
   "metadata": {},
   "source": [
    "2. Describe how the Market Basket Research makes use of association analysis concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca18d85d",
   "metadata": {},
   "source": [
    "Ans:\n",
    "Market Basket Analysis makes use of association analysis concepts to identify relationships between products that are frequently purchased together. It involves measuring the likelihood of co-occurrence of items in customer transactions to uncover meaningful associations. This helps businesses understand customer buying behavior and optimize various aspects of their operations such as product placement, marketing strategies, and cross-selling efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb440ff",
   "metadata": {},
   "source": [
    "3. Give an example of the Apriori algorithm for learning association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fedfdd9",
   "metadata": {},
   "source": [
    "Ans: Example: Suppose you have a transaction dataset from a grocery store:\n",
    "\n",
    "Transaction 1: Bread, Milk\n",
    "Transaction 2: Bread, Diaper, Beer\n",
    "Transaction 3: Milk, Diaper, Beer, Eggs\n",
    "Transaction 4: Bread, Milk, Diaper, Beer\n",
    "Transaction 5: Bread, Milk, Diaper, Eggs\n",
    "\n",
    "Using the Apriori algorithm to find association rules with a minimum support of 40% and confidence of 60%:\n",
    "\n",
    "Identify frequent 1-item sets:\n",
    "\n",
    "Bread: 4 occurrences (80%)\n",
    "Milk: 4 occurrences (80%)\n",
    "Diaper: 3 occurrences (60%)\n",
    "Beer: 3 occurrences (60%)\n",
    "Eggs: 2 occurrences (40%)\n",
    "Generate candidate 2-item sets:\n",
    "\n",
    "Bread, Milk: 3 occurrences (60%)\n",
    "Bread, Diaper: 2 occurrences (40%)\n",
    "Bread, Beer: 2 occurrences (40%)\n",
    "Milk, Diaper: 2 occurrences (40%)\n",
    "Milk, Beer: 2 occurrences (40%)\n",
    "Calculate support and confidence for the 2-item sets:\n",
    "\n",
    "Bread -> Milk: Support = 60%, Confidence = 75%\n",
    "Bread -> Diaper: Support = 40%, Confidence = 50%\n",
    "Bread -> Beer: Support = 40%, Confidence = 50%\n",
    "Milk -> Diaper: Support = 40%, Confidence = 50%\n",
    "Milk -> Beer: Support = 40%, Confidence = 50%\n",
    "Based on the specified minimum support and confidence thresholds, the algorithm would consider the association rule \"Bread -> Milk\" as significant, indicating that customers who buy bread are likely to buy milk as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c718d",
   "metadata": {},
   "source": [
    "4. In hierarchical clustering, how is the distance between clusters measured? Explain how this metric is used to decide when to end the iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9818329e",
   "metadata": {},
   "source": [
    "Ans: \n",
    "In hierarchical clustering, the distance between clusters is measured using various metrics, such as:\n",
    "\n",
    "1.Single Linkage (Minimum): Distance between the closest points in two clusters.\n",
    "2.Complete Linkage (Maximum): Distance between the farthest points in two clusters.\n",
    "3.Average Linkage: Average distance between all pairs of points in two clusters.\n",
    "4.Centroid Linkage: Distance between the centroids of two clusters.\n",
    "5.Ward's Linkage: Measures the increase in the sum of squared distances after merging clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a90b08",
   "metadata": {},
   "source": [
    "5. In the k-means algorithm, how do you recompute the cluster centroids?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427523b",
   "metadata": {},
   "source": [
    "Ans: In the k-means algorithm, to recompute the cluster centroids:\n",
    "\n",
    "For each cluster:\n",
    "Calculate the mean (centroid) of all data points belonging to that cluster.\n",
    "Set the cluster's centroid to the calculated mean.\n",
    "Repeat this process for all clusters.\n",
    "This updates the centroids based on the current assignment of data points to clusters. The algorithm iteratively refines the centroids until convergence, where the centroids stabilize and the assignments remain relatively unchanged.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6dba5",
   "metadata": {},
   "source": [
    "6. At the start of the clustering exercise, discuss one method for determining the required number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e2b83",
   "metadata": {},
   "source": [
    "Ans: \n",
    "One method for determining the required number of clusters at the start of a clustering exercise is the \"Elbow Method\":\n",
    "\n",
    "Compute the sum of squared distances (SSE) for different values of k (number of clusters).\n",
    "Plot the SSE values against the corresponding k values.\n",
    "Look for the \"elbow point\" on the plot, where the rate of SSE reduction slows down significantly.\n",
    "The point where the SSE starts to level off can indicate a reasonable number of clusters to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d6cdbe",
   "metadata": {},
   "source": [
    "7. Discuss the k-means algorithm's advantages and disadvantages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41c942",
   "metadata": {},
   "source": [
    "Ans: \n",
    "  \n",
    "    Advantages of the k-means algorithm:\n",
    "\n",
    "1.Simple and Fast: K-means is computationally efficient and works well with large datasets.\n",
    "2.Scalability: It can handle large datasets and is well-suited for high-dimensional data.\n",
    "3.Easy Interpretation: Results are easily understandable as clusters are defined by their centroids.\n",
    "4.Applicability: Effective for data with well-defined spherical clusters.\n",
    "\n",
    "     Disadvantages of the k-means algorithm:\n",
    "\n",
    "1.Sensitive to Initialization: The final clusters can vary based on initial centroid placement.\n",
    "2.Requires Predefined k: The number of clusters needs to be specified beforehand.\n",
    "3.Sensitive to Outliers: Outliers can significantly affect centroid calculation.\n",
    "4.Assumes Equal Variance: Assumes that clusters have similar sizes and variances.\n",
    "5.Not Suitable for Non-Globular Shapes: Struggles with clusters of non-spherical or complex shapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30386890",
   "metadata": {},
   "source": [
    "8. Draw a diagram to demonstrate the principle of clustering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07763a",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    \n",
    "    Here's a textual description of a simple diagram representing the principle of clustering:\n",
    "\n",
    "1.Data Points: Start with a set of data points in a two-dimensional space. Each data point is represented as a dot on the graph.\n",
    "\n",
    "2.Initial Random Clusters: Initially, you might imagine these data points scattered across the space. To begin clustering, create a few initial random clusters. Each cluster is represented by a different color or shape.\n",
    "\n",
    "3.Distance Calculation: Calculate the distance between each data point and the center of each cluster (often using a distance metric like Euclidean distance).\n",
    "\n",
    "4.Assigning to Nearest Cluster: Assign each data point to the cluster whose center is closest to it. This creates the initial grouping of data points.\n",
    "\n",
    "5.Update Cluster Centers: Calculate the new center of each cluster by taking the mean of all the data points assigned to that cluster.\n",
    "\n",
    "6.Re-assignment: Re-assign each data point to the cluster whose new center is closest to it. This step might involve changing the assignments of some data points.\n",
    "\n",
    "7.Iteration: Steps 5 and 6 are repeated iteratively until the cluster assignments stabilize. This means that the data points are no longer changing their assigned clusters significantly.\n",
    "\n",
    "8.Final Clusters: The result is a set of clusters where data points within each cluster are more similar to each other in comparison to points in other clusters. The clusters are compact and well-defined, demonstrating the principle of grouping similar data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bdded4",
   "metadata": {},
   "source": [
    "9. During your study, you discovered seven findings, which are listed in the data points below. Using the K-means algorithm, you want to build three clusters from these observations. The clusters C1, C2, and C3 have the following findings after the first iteration:\n",
    "\n",
    "C1: (2,2), (4,4), (6,6); C2: (2,2), (4,4), (6,6); C3: (2,2), (4,4),\n",
    "\n",
    "C2: (0,4), (4,0), (0,4), (0,4), (0,4), (0,4), (0,4), (0,4), (0,\n",
    "\n",
    "C3: (5,5) and (9,9)\n",
    "\n",
    "What would the cluster centroids be if you were to run a second iteration? What would this clustering's SSE be?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c260f8e",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "C1: (2,2), (4,4), (6,6)\n",
    "C2: (0,4), (4,0), (0,4), (0,4), (0,4), (0,4), (0,4), (0,4), (0,4)\n",
    "C3: (5,5), (9,9)\n",
    "\n",
    "Let's calculate the cluster centroids for the second iteration:\n",
    "\n",
    "Cluster C1:\n",
    "New centroid = ((2+4+6)/3, (2+4+6)/3) = (4, 4)\n",
    "\n",
    "Cluster C2:\n",
    "New centroid = ((0+4+0+0+0+0+0+0+0)/9, (4+0+4+4+4+4+4+4+4)/9) = (0.44, 3.56)\n",
    "\n",
    "Cluster C3:\n",
    "New centroid = ((5+9)/2, (5+9)/2) = (7, 7)\n",
    "\n",
    "Now, let's calculate the Sum of Squared Errors (SSE) for this clustering:\n",
    "\n",
    "SSE = Sum of squared distances of data points to their respective cluster centroids\n",
    "\n",
    "For Cluster C1:\n",
    "SSE_C1 = (2-4)^2 + (2-4)^2 + (4-4)^2 = 8 + 8 + 0 = 16\n",
    "\n",
    "For Cluster C2:\n",
    "SSE_C2 = (0-0.44)^2 + (4-3.56)^2 + (0-0.44)^2 + (0-0.44)^2 + (0-0.44)^2 + (0-0.44)^2 + (0-0.44)^2 + (0-0.44)^2 + (0-0.44)^2 = 0.1936 + 0.1936 + 0.1936 + 0.1936 + 0.1936 + 0.1936 + 0.1936 + 0.1936 + 0.1936 = 1.7424\n",
    "\n",
    "For Cluster C3:\n",
    "SSE_C3 = (5-7)^2 + (5-7)^2 + (9-7)^2 = 4 + 4 + 4 = 12\n",
    "\n",
    "Total SSE = SSE_C1 + SSE_C2 + SSE_C3 = 16 + 1.7424 + 12 = 29.7424\n",
    "\n",
    "So, after the second iteration, the cluster centroids and the SSE for the clustering would be:\n",
    "C1: (4, 4)\n",
    "C2: (0.44, 3.56)\n",
    "C3: (7, 7)\n",
    "Total SSE: 29.7424\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc0a92",
   "metadata": {},
   "source": [
    "10. In a software project, the team is attempting to determine if software flaws discovered during testing are identical. Based on the text analytics of the defect details, they decided to build 5 clusters of related defects. Any new defect formed after the 5 clusters of defects have been identified must be listed as one of the forms identified by clustering. A simple diagram can be used to explain this process. Assume you have 20 defect data points that are clustered into 5 clusters and you used the k-means algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d77f7",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "    Diagram Description: Identifying Clusters of Software Defects\n",
    "\n",
    "Data Points: Draw a set of 20 points on the diagram, representing the defect data points. Label them as D1, D2, ..., D20.\n",
    "\n",
    "Initial Clusters: Divide these points into 5 clusters. Each cluster can be represented by a different color or shape. Label these clusters as Cluster 1, Cluster 2, ..., Cluster 5.\n",
    "\n",
    "K-Means Process:\n",
    "\n",
    "Iteration 1: Run the K-means algorithm on the data points. Calculate the centroids of each cluster based on the data points assigned to them.\n",
    "Iteration 2: Re-run the algorithm to refine the clusters. The centroids of each cluster will move closer to the center of the data points within that cluster.\n",
    "Continue iterating until the centroids stabilize.\n",
    "Final Clusters: After convergence, you'll have 5 well-defined clusters of defects. Each defect should belong to one of these clusters based on their similarities.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
