{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6404e19",
   "metadata": {},
   "source": [
    "1. In a linear equation, what is the difference between a dependent variable and an independent variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70e4b0",
   "metadata": {},
   "source": [
    "Ans:\n",
    "The independent variable is the input or factor that is manipulated, while the dependent variable is the outcome that changes in response to the independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bc744",
   "metadata": {},
   "source": [
    "2. What is the concept of simple linear regression? Give a specific example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb502977",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    Simple linear regression is a statistical method used to model the relationship between two variables: one independent variable and one dependent variable. It seeks to find a linear equation that best fits the data points and allows for predicting the dependent variable based on the independent variable.\n",
    "\n",
    "Example: Let's say we're studying the relationship between hours studied (independent variable) and exam scores (dependent variable). We collect data from several students and plot their hours studied against their exam scores. Simple linear regression would help us find a line that best represents the trend in the data, allowing us to predict exam scores based on the number of hours studied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ab13f",
   "metadata": {},
   "source": [
    "3. In a linear regression, define the slope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d92d33",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    The slope in a linear regression represents the rate of change of the dependent variable with respect to a one-unit change in the independent variable. It indicates how much the dependent variable's value is expected to increase or decrease for each unit change in the independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd052f8",
   "metadata": {},
   "source": [
    "4. Determine the graph's slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b22ec",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    The slope of the graph is undefined (or \"no slope\") because the y-coordinate (2) remains constant regardless of the change in the x-coordinate. In other words, the line is horizontal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f74e8",
   "metadata": {},
   "source": [
    "5. In linear regression, what are the conditions for a positive slope?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f359f56",
   "metadata": {},
   "source": [
    "In linear regression, for a positive slope, the data points should generally show an increasing trend, where higher values of the independent variable are associated with higher values of the dependent variable. This means that as the independent variable increases, the dependent variable tends to increase as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffd9f6",
   "metadata": {},
   "source": [
    "6. In linear regression, what are the conditions for a negative slope?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f21bdc7",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    In linear regression, for a negative slope, the data points should generally exhibit a decreasing trend, where higher values of the independent variable are associated with lower values of the dependent variable. This means that as the independent variable increases, the dependent variable tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfcfd62",
   "metadata": {},
   "source": [
    "7. What is multiple linear regression and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b4869",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    Multiple linear regression is a statistical technique used to model the relationship between multiple independent variables and a single dependent variable. It extends the concept of simple linear regression, which involves only one independent variable, to cases where there are two or more independent variables.\n",
    "    \n",
    "    In multiple linear regression, the goal is to find the best-fitting linear equation that explains how the combination of independent variables influences the dependent variable. Each independent variable is assigned a coefficient that represents its contribution to the dependent variable's change, while accounting for the influences of the other independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243871d1",
   "metadata": {},
   "source": [
    "8. In multiple linear regression, define the number of squares due to error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dba346",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    The sum of squares due to error (SSE) in multiple linear regression represents the sum of the squared differences between the actual values of the dependent variable and the predicted values obtained from the regression equation. It quantifies the overall unexplained variability or \"error\" in the model's predictions. Minimizing the SSE is a key objective in regression analysis, as it leads to a better-fitting model that explains as much of the variance in the dependent variable as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76928f65",
   "metadata": {},
   "source": [
    "9. In multiple linear regression, define the number of squares due to regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0aa85",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    The sum of squares due to regression (SSR) in multiple linear regression represents the sum of the squared differences between the predicted values of the dependent variable obtained from the regression equation and the mean of the dependent variable. It quantifies the variability in the dependent variable that is explained by the regression model. In other words, SSR measures how well the independent variables in the model account for the variation in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a24d90",
   "metadata": {},
   "source": [
    "11. What is heteroskedasticity, and what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0608ee",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    \n",
    "Heteroskedasticity refers to a pattern in statistical data where the variability of the residuals (the differences between actual and predicted values) changes as the values of the independent variable(s) change. In simpler terms, it means that the spread or dispersion of the residuals is not consistent across the range of the independent variable(s). This can indicate that the variability of errors is unequal, potentially affecting the reliability of a regression model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135ea3e",
   "metadata": {},
   "source": [
    "12. Describe the concept of ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337272e",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    Ridge regression is a regularization technique used in linear regression to prevent overfitting by adding a penalty term to the regression equation. This penalty term is based on the sum of squared values of the coefficients, scaled by a parameter (lambda or Î±). Ridge regression helps to constrain the coefficients from becoming too large, which can lead to unstable and overfit models. It aims to find a balance between fitting the data well and preventing excessive reliance on any one predictor variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb506a",
   "metadata": {},
   "source": [
    "13. Describe the concept of lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d72934",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    Lasso regression (Lasso stands for \"Least Absolute Shrinkage and Selection Operator\") is a regularization method in linear regression. It adds a penalty term to the regression equation, like ridge regression, but with a different approach. Lasso introduces a penalty based on the absolute values of the coefficients. This penalty encourages some coefficients to be exactly zero, effectively performing variable selection and leading to a sparse model. Lasso is useful for feature selection and reducing the impact of irrelevant or less important predictor variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66866de",
   "metadata": {},
   "source": [
    "14. What is polynomial regression and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d7b28",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    Polynomial regression is a type of regression analysis where the relationship between the independent and dependent variables is modeled using a polynomial equation. Instead of a linear equation, polynomial regression allows for fitting curves and nonlinear relationships in the data. This is achieved by including higher-degree polynomial terms (e.g., quadratic, cubic) in the regression equation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd74ceb",
   "metadata": {},
   "source": [
    "\n",
    "15. Describe the basis function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c906b7",
   "metadata": {},
   "source": [
    "Ans: A basis function is a mathematical function used to represent complex functions by combining multiple simpler functions. These simpler functions form a basis set, and any complex function can be approximated or expressed as a linear combination of these basis functions. They are commonly used in fields like signal processing, linear algebra, and machine learning for dimensionality reduction and function approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4fc3ea",
   "metadata": {},
   "source": [
    "16. Describe how logistic regression works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f59100",
   "metadata": {},
   "source": [
    "Ans: Logistic regression is a binary classification algorithm that works by modeling the probability of an input belonging to a certain class. It uses the logistic function (also known as the sigmoid function) to map input features to a probability score between 0 and 1. The algorithm learns the optimal coefficients for these features through iterative optimization techniques, aiming to minimize the difference between predicted probabilities and actual class labels in the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
