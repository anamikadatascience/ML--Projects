{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bcd2bf",
   "metadata": {},
   "source": [
    "1. What is prior probability? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e79c0",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "    Prior probability refers to the initial probability assigned to an event or hypothesis based on existing knowledge, information, or beliefs before new evidence or data is considered. It represents your subjective belief about the likelihood of an event occurring before any specific data is taken into account.\n",
    "\n",
    "Example: Let's say you're trying to predict whether a flipped coin will land heads or tails. Before flipping the coin, you might assign a prior probability of 0.5 (50%) to each outcome because you believe the coin is fair. This is your initial belief about the likelihood of heads or tails without any additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae8d15",
   "metadata": {},
   "source": [
    "2. What is posterior probability? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6239d70",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "        Posterior probability is the updated probability of an event or hypothesis after considering new evidence or data, taking into account both prior beliefs and the observed information. It's calculated using Bayes' theorem, which combines the prior probability and the likelihood of the new evidence.\n",
    "\n",
    "Example: Consider a medical test to determine if a person has a certain disease. The prior probability might be your initial belief about the likelihood of a person having the disease based on general prevalence. After conducting the test and obtaining the test results, you calculate the posterior probability, incorporating the test's accuracy and the person's test result. This new probability reflects your updated belief about the person having the disease based on the test's outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78448a0",
   "metadata": {},
   "source": [
    "3. What is likelihood probability? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c8480",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "    Likelihood probability refers to the probability of observing certain data or evidence given a specific hypothesis or model. It represents how well the hypothesis explains the observed data.\n",
    "\n",
    "Example: In a coin toss experiment, if you're trying to determine whether the coin is fair (50% chance of heads and 50% chance of tails), the likelihood probability would describe how likely you are to observe a specific sequence of heads and tails outcomes under the assumption of a fair coin. If you flip the coin five times and get HHTTH, the likelihood probability would reflect how well the hypothesis of a fair coin explains this specific sequence of outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0334a26c",
   "metadata": {},
   "source": [
    "4. What is Naïve Bayes classifier? Why is it named so?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4507582f",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    The Naïve Bayes classifier is a machine learning algorithm used for classification tasks, such as text classification or spam detection. It's based on Bayes' theorem and assumes that features (attributes) are conditionally independent given the class label, even though this might not be true in reality. Despite its simplifying assumption, it often performs well in practice.\n",
    "\n",
    "It's named \"Naïve\" because of the assumption of independence among features, which is rarely true for real-world data. Despite this overly simplified assumption, Naïve Bayes can still provide surprisingly accurate results in various applications, making it a useful and straightforward classification approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df95e4",
   "metadata": {},
   "source": [
    "5. What is optimal Bayes classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c8689b",
   "metadata": {},
   "source": [
    "Ans:\n",
    "The Optimal Bayes Classifier is like a super-smart way of categorizing things. It's the best possible method when we know exactly how likely different things are to happen. But in the real world, we usually don't know these exact chances, so we use simpler methods, like the Naïve Bayes classifier or other smart algorithms, to make educated guesses about categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d5e4d",
   "metadata": {},
   "source": [
    "6. Write any two features of Bayesian learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca68be",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "1. Probabilistic Foundation: Bayesian learning methods are grounded in probability theory and Bayes' theorem, allowing them to model uncertainty and make decisions based on calculated probabilities.\n",
    "\n",
    "2. Adaptability: These methods can update their beliefs as new data is observed, enabling them to continuously improve their predictions and adapt to changing environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ea77c",
   "metadata": {},
   "source": [
    "7. Define the concept of consistent learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc956e95",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "Consistent Learners: Consistent learners are like students who study more and more, and as they learn from more examples, they start getting answers right most of the time. So, the more examples they have, the better their predictions become, and they make fewer mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c8d5a9",
   "metadata": {},
   "source": [
    "8. Write any two strengths of Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52611234",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "1. Simple and Fast: \n",
    "The Bayes classifier is straightforward to understand and quick to compute. It doesn't require a lot of complicated calculations, which makes it efficient for many tasks.\n",
    "\n",
    "2. Effective with Small Data:\n",
    "Even if you don't have a ton of data, the Bayes classifier can still work well. It's good at making predictions even when you have just a few examples to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84379489",
   "metadata": {},
   "source": [
    "9. Write any two weaknesses of Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84424883",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "1. Naïve Assumption:\n",
    "The Bayes classifier assumes that all the features are independent, which might not be true in real life. This simplification can lead to inaccurate predictions when features are actually related.\n",
    "\n",
    "2. Limited Expressiveness:\n",
    "The Bayes classifier might not capture complex relationships in the data very well. It's not the best choice for tasks where the relationships between features are intricate or nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ece855",
   "metadata": {},
   "source": [
    "10. Explain how Naïve Bayes classifier is used for\n",
    "\n",
    "        1. Text classification\n",
    "\n",
    "        2. Spam filtering\n",
    "\n",
    "       3. Market sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360854a4",
   "metadata": {},
   "source": [
    "Ans: \n",
    "    \n",
    "    1.Text Classification:\n",
    "\n",
    "Collect Training Data: Gather a bunch of text examples with known categories (like \"sports,\" \"politics,\" etc.).\n",
    "Learn the Words: Count how often each word appears in each category.\n",
    "Calculate Probabilities: For a new text, calculate how likely it belongs to each category using Bayes' theorem.\n",
    "Choose the Category: Pick the category with the highest probability as the classification result.\n",
    "Adapt as Needed: As more examples come in, update the word counts and probabilities to make the classifier better.\n",
    "    \n",
    "2. Spam Filtering:\n",
    "\n",
    "Training Data: Collect emails labeled as spam or not.\n",
    "Word Frequencies: Count how often words appear in spam and non-spam emails.\n",
    "Probabilities: Use Bayes' theorem to calculate the chance an email is spam based on word frequencies.\n",
    "Threshold: Set a threshold, like 90%, for an email to be considered spam.\n",
    "Filtering: Emails with probabilities above the threshold are marked as spam.\n",
    "    \n",
    "3.Market Sentiment Analysis:\n",
    "\n",
    "Collect Data: Gather texts (like tweets) about a certain market or product.\n",
    "Sentiment Labels: Assign positive or negative labels to these texts based on their meaning.\n",
    "Word Analysis: Calculate how often certain words appear in positive/negative texts.\n",
    "Bayesian Calculation: Compute probabilities of positive or negative sentiment given the words.\n",
    "Sentiment Prediction: For new texts, calculate the probabilities and predict positive/negative sentiment based on which probability is higher.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
